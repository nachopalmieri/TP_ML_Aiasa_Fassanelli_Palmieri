{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef25ec7f",
   "metadata": {},
   "source": [
    "## Trabajo Práctico 3: Detectando atributos de personas\n",
    "\n",
    "### Grupo 4  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4771b4",
   "metadata": {},
   "source": [
    "A partir de un conjunto de datos que contiene imagenes recortadas de personas, desarrollaremos un modelo que sea capaz de detectar si la persona tiene o no barba. Utilizaremos la columna \"No_beard\" como target. Los valores de salida pueden ser: \"Sin Barba\" y \"Con Barba\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe46b27",
   "metadata": {},
   "source": [
    "### Setup inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20689f",
   "metadata": {},
   "source": [
    "#### Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6983fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "\n",
    "# Lib para trabajar con arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# libs que usamos para construir y entrenar redes neuronales, y que además tiene utilidades para leer sets de \n",
    "# imágenes\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report,balanced_accuracy_score\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea05f9",
   "metadata": {},
   "source": [
    "#### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f841120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path con la ruta con las imágenes\n",
    "IMAGES_DIR = Path('./dataset/img_align_celeba/img_align_celeba/')\n",
    "ATRIBUTOS_DIR = Path('./dataset/list_attr_celeba.csv')\n",
    "PARTICIONES_DIR = Path('./dataset/list_eval_partition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995f96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables a utilizar\n",
    "SIZE = 70\n",
    "IMAGES_CHANNELS = 3\n",
    "BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "119512b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizamos solamente la columna \"No_Beard\"\n",
    "data = pd.read_csv(ATRIBUTOS_DIR,sep=',',usecols=['image_id','No_Beard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed1002b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazamos los valores = 1 por 'Si' y los valores = -1 por 'No'\n",
    "data['No_Beard']=data['No_Beard'].replace([1], 'No_Barba')\n",
    "data['No_Beard']=data['No_Beard'].replace([-1], 'Barba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d969ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos divididos en diferentes conjuntos para armar: train, test y validation\n",
    "data_partition = pd.read_csv(PARTICIONES_DIR,sep=',',usecols=['image_id','partition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877b2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unifico data_partition con data para dividir el dataset en conjuntos: train, test y validation\n",
    "df_merge = pd.merge(data, data_partition, how='inner', on = 'image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379cbd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chequeo que se unifiquen todos\n",
    "df_merge.partition.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f3dec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conjunto Train, Test, Validation\n",
    "\n",
    "train = df_merge[df_merge['partition'] == 0]\n",
    "test = df_merge[df_merge['partition'] == 1]\n",
    "validation = df_merge[df_merge['partition'] == 2]\n",
    "\n",
    "#Eliminamos la columna del nro de particion\n",
    "train = train.drop(['partition'],axis = 1)\n",
    "test = test.drop(['partition'],axis = 1)\n",
    "validation = validation.drop(['partition'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f6b3a4",
   "metadata": {},
   "source": [
    "### 1. Análisis exploratorio sobre el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2977e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para devolver ejemplos del dataset\n",
    "def sample_images(dataset, n, figsize=(10, 5), image_width=SIZE, image_height=SIZE):\n",
    "    samples = data.sample(n)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "    for i in range(n):\n",
    "        image = load_img(os.path.join(dataset, samples.iloc[i]['image_id']))\n",
    "        image = image.resize((image_width, image_height))\n",
    "        image = img_to_array(image)\n",
    "        image = datagen.standardize(image)\n",
    "\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"{samples.iloc[i]['No_Beard']}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec063c",
   "metadata": {},
   "source": [
    "#### Volumetría de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d511dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad total de imágenes:\", len(df_merge))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9456bd",
   "metadata": {},
   "source": [
    "#### Distribución de la variable a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2ec9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_df = df_merge.No_Beard.value_counts()\n",
    "names_df = vals_df.index\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "ax_train = fig.add_subplot(1, 3, 1)\n",
    "ax_train.pie(vals_df, labels=names_df, autopct='%1.1f%%')\n",
    "ax_train.set_title('Distribución conjunto total')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e18efab",
   "metadata": {},
   "source": [
    "Podemos ver en los gráficos que la variable target se encuentra desbalanceada. Más del 80% de las imágenes de las personas en el dataset, no tienen barba. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc69d3d",
   "metadata": {},
   "source": [
    "#### Balanceo del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3692c69a",
   "metadata": {},
   "source": [
    "Realizamos undersampling para eliminar aleatoriamente muestras de la clase mayoritaria y así poder igualar el número de muestras de la clase minoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d561768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = df_merge[\"No_Beard\"].value_counts()\n",
    "higher_category = list(target_count.index)[0]\n",
    "np.random.seed(42)\n",
    "indices = df_merge[df_merge[\"No_Beard\"] == higher_category].index\n",
    "sample_size = target_count[0] - target_count[1]\n",
    "\n",
    "drop_sample = np.random.choice(indices, sample_size, replace = False)\n",
    "df_merge_opt = df_merge.drop(drop_sample, axis = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04431b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_df = df_merge_opt.No_Beard.value_counts()\n",
    "names_df = vals_df.index\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "ax_train = fig.add_subplot(1, 3, 1)\n",
    "ax_train.pie(vals_df, labels=names_df, autopct='%1.1f%%')\n",
    "ax_train.set_title('Distribución conjunto total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55e26071",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_merge_opt[df_merge_opt['partition'] == 0]\n",
    "test = df_merge_opt[df_merge_opt['partition'] == 1]\n",
    "validation = df_merge_opt[df_merge_opt['partition'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8704bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_train = train.No_Beard.value_counts()\n",
    "names_train = vals_train.index\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "ax_train = fig.add_subplot(1, 3, 1)\n",
    "ax_train.pie(vals_train, labels=names_train, autopct='%1.1f%%')\n",
    "ax_train.set_title('Distribución conjunto Train')\n",
    "\n",
    "\n",
    "vals_test = test.No_Beard.value_counts()\n",
    "names_test = vals_test.index\n",
    "ax_test = fig.add_subplot(1, 3, 2)\n",
    "ax_test.pie(vals_test, labels=names_test, autopct='%1.1f%%')\n",
    "ax_test.set_title('Distribución conjunto Test')\n",
    "\n",
    "vals_val = validation.No_Beard.value_counts()\n",
    "names_val = vals_val.index\n",
    "ax_val = fig.add_subplot(1, 3, 3)\n",
    "ax_val.pie(vals_val, labels=names_val, autopct='%1.1f%%')\n",
    "ax_val.set_title('Distribución conjunto Validation')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61f18440",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de imágenes y dimensiones en Train:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3f4c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de imágenes y dimensiones en Test:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fd8b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de imágenes y dimensiones en Validation:\", validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c9a78",
   "metadata": {},
   "source": [
    "#### Estructura y tipo de las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97bb95",
   "metadata": {},
   "source": [
    "El conjunto de imágenes originales tienen una dimensión de 178x218 pixeles y son a color, por lo tanto tienen 3 canales de profundidad. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c658b633",
   "metadata": {},
   "source": [
    "##### Ejemplos de las imágenes originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "841a2c6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_images(IMAGES_DIR, 5, figsize=(10, 5), image_width=178, image_height=218)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a0404",
   "metadata": {},
   "source": [
    "##### Ejemplos de las imágenes modificadas en tamaño y reescaladas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c4f8b",
   "metadata": {},
   "source": [
    "No contamos con una GPU para entrenar los modelos, por lo tanto: \n",
    "- Reducimos el tamaño a 70x70 pixeles: de esta manera, cada modelo tiene que aprender una menor cantidad de pesos, entonces, los resultados se obtienen más rápido. \n",
    "- Reescalamos los valores de las imágenes entre 0 y 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "998acc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lector de imágenes que se encarga de reescalarlas. \n",
    "images_reader = ImageDataGenerator(\n",
    "    rescale=1/255\n",
    ")\n",
    "\n",
    "#Definimos un generador de DataFrame para cada conjunto de Datos. \n",
    "\n",
    "train_generator = images_reader.flow_from_dataframe(\n",
    "    #DataFrame que contiene el nombre de las imagenes y la variable target. \n",
    "    dataframe = train,\n",
    "    #Path que contiene todas las imágenes\n",
    "    directory=IMAGES_DIR,\n",
    "    #Columna del DataFrame que contiene el nombre de las imágenes\n",
    "    x_col='image_id',\n",
    "    #Columna target del DataFrame. \n",
    "    y_col='No_Beard',\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    target_size=(SIZE, SIZE)\n",
    ")\n",
    "\n",
    "test_generator = images_reader.flow_from_dataframe(\n",
    "    #DataFrame que contiene el nombre de las imagenes y la variable target. \n",
    "    dataframe = test,\n",
    "    #Path que contiene todas las imágenes\n",
    "    directory=IMAGES_DIR,\n",
    "    #Columna del DataFrame que contiene el nombre de las imágenes\n",
    "    x_col='image_id',\n",
    "    #Columna target del DataFrame. \n",
    "    y_col='No_Beard',\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    target_size=(SIZE, SIZE)\n",
    ")\n",
    "\n",
    "validation_generator = images_reader.flow_from_dataframe(\n",
    "    #DataFrame que contiene el nombre de las imagenes y la variable target. \n",
    "    dataframe = validation,\n",
    "    #Path que contiene todas las imágenes\n",
    "    directory=IMAGES_DIR,\n",
    "    #Columna del DataFrame que contiene el nombre de las imágenes\n",
    "    x_col='image_id',\n",
    "    #Columna target del DataFrame. \n",
    "    y_col='No_Beard',\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    target_size=(SIZE, SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c5ff654",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images(IMAGES_DIR, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c141c7a",
   "metadata": {},
   "source": [
    "### 2. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39f8cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Función para graficar la curva de aprendizaje: \n",
    "def learning_curve(historial):\n",
    "    plt.plot(historial.history['accuracy'], label='train')\n",
    "    plt.plot(historial.history['val_accuracy'], label='test')\n",
    "    plt.title('Accuracy durante el entrenamiento')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1061a92f",
   "metadata": {},
   "source": [
    "Para las redes neuronales de tipo MLP utilizamos los siguientes parámetros en común: \n",
    "- Primer capa **Flatten** que recibe una imágen de 70x70x3. \n",
    "- Función de activación en la capa de salida: **Sigmoide**. \n",
    "- Se trata de una clasificación binaria, que indica si la imágen de la persona tiene barba (No_Beard = 1) o no (No_Beard = 0). Utilizamos una función de error de tipo **Binary_crossentropy** ya que son redes que tienen una sóla salida entre 0 y 1. \n",
    "- La métrica utilizada es \"Accuracy\" ya que la distribución de la variable target está balanceada. \n",
    "- Empezamos utilizando 10 épocas, luego fuimos variando según cada caso. \n",
    "- El resto de los hiperparámetros lo fuimos modificando para cada red neuronal propuesta. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fcc327",
   "metadata": {},
   "source": [
    "Red Neuronal 1:\n",
    "- MLP\n",
    "- Capas ocultas: 2 densas, con 20 neuronas y 15 neuronas. \n",
    "- Capa de salida: Densa con 1 neurona. \n",
    "- Dropout: no utilizado.\n",
    "- Función de activación: \"relu\" para las primeras capas. \n",
    "- Épocas: 10. \n",
    "- Tamaño de Batch: 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24eea35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_1 = Sequential([\n",
    "    Flatten(input_shape=(SIZE,SIZE,IMAGES_CHANNELS)), \n",
    "    \n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(15, activation='relu'),\n",
    "    \n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model_mlp_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572697a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_1 = model_mlp_1.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c002e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
